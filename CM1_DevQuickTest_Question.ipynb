{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/llu13701/cm1_python_test/blob/main/CM1_DevQuickTest_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHaZgOQJ_cH2"
   },
   "source": [
    "### Test Instructions\n",
    "The purpose of this simple coding test is to allow us to get a grasp on the quality of your code and to identify the role that would suit you best within our team. You don't NEED to be able to answer all of the items, but the ones that you do answer need to be correct. Feel free to use Google or any other tools that you prefer to complete these tasks.\n",
    "\n",
    "Install any needed third-party libraries below this block. Please install the minimum amount of libraries you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DS8Y5bTE_cNX"
   },
   "source": [
    "!pip install whatever_you_need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeZ98TNS_ZDK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "\n",
    "import os\n",
    "import discord\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain import chat_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tT8GriLI_qcl"
   },
   "source": [
    "### Task 1 (Data manipulation / Visualization)\n",
    "Download the file: https://drive.google.com/file/d/1R_M3xI3b_BqAN_xWLqJDneg273X_sok5/view?usp=sharing\n",
    "\n",
    "In `message_data.csv` there's two columns, one corresponds to the unique id of someone sending a message and the other one to when they sent it.\n",
    "\n",
    "Generate an interactive chart that shows the percentage of daily messages sent by new users (those who sent their first message ever on a given day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "gMe_jfXp_2zu",
    "outputId": "519b7f24-5911-45b6-ad3a-218ad4aecbf0"
   },
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDe4I-E-_1M-"
   },
   "source": [
    "### Task 2 (Django)\n",
    "**To take the django portion of this test go to: https://github.com/llu13701/cm1_python_test and follow the instructions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hF_IbJXY_rV5"
   },
   "outputs": [],
   "source": [
    "<https://github.com/zeebrow/django_reddit.git>\n",
    "\n",
    "### 1 name and date\n",
    "\n",
    "<img src='djangopics/1-name-date.png'>\n",
    "\n",
    "### 2 show url and link to comments\n",
    "\n",
    "<img src='djangopics/2-link-to-comments-show-link.png'>\n",
    "\n",
    "### 3 profile with submissions and comments\n",
    "\n",
    "<img src='djangopics/3-profile-submissions-comments.png'>\n",
    "\n",
    "### 4 edit dialog\n",
    "\n",
    "<img src='djangopics/4-1-needs-edit.png'>\n",
    "<img src='djangopics/4-2-edited.png'>\n",
    "\n",
    "### 5 video of edits\n",
    "\n",
    "<https://youtu.be/fuyMKXz_H7Q>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6MoFpH7_tn2"
   },
   "source": [
    "### Task 3 (LangChain)\n",
    "Write a simple Chain that does the following:\n",
    "- Uses openai's gpt-3.5-turbo model.\n",
    "- Remembers the last 2 message exchanges, as well as the system message.\n",
    "- Greets people and tells a joke about their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flO7_-oA_xXv"
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "\n",
    "chat = chat_models.ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "SPECIAL_SAUCE = \"Be kid-friendly.\"\n",
    "# SPECIAL_SAUCE = \"Be absolutely brutal. Show no mercy, nor apologies.\"\n",
    "# SPECIAL_SAUCE = \"Make sure the joke would be awesome to tell during a job interview.\"\n",
    "system_prompt_template = \"Greet the discord users with a joke about their name.\"\n",
    "system_prompt_template = \" \".join([\n",
    "    system_prompt_template, \n",
    "    SPECIAL_SAUCE, \n",
    "    \"Do not respond with questions.\",\n",
    "])\n",
    "human_prompt_template = \"{username} has joined.\"\n",
    "\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=system_prompt_template,\n",
    "        input_variables=[]\n",
    "    )\n",
    ")\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "name = input(\"what is your discord name? \")\n",
    "\n",
    "human_prompt_username = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=human_prompt_template,\n",
    "        input_variables=['username']\n",
    "    )\n",
    ")\n",
    "\n",
    "history.add_message(system_prompt)\n",
    "history.add_message(human_prompt_username.format(username=name))\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(history.messages)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "cr = chain.run({'username': name})\n",
    "print(cr)\n",
    "history.add_ai_message(cr)\n",
    "\n",
    "response_text = input(\"Tell the chatbot what you thought of the joke! \")\n",
    "human_prompt_response = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"{text}\",\n",
    "        input_variables=['text']\n",
    "    )\n",
    ")\n",
    "\n",
    "history.add_message(human_prompt_response.format(text=response_text))\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(history.messages)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "cr = chain.run({\n",
    "    'username': name,\n",
    "    'text' : response_text\n",
    "})\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMAawESH_32U"
   },
   "source": [
    "### Task 4 (Discord API)\n",
    "\n",
    "Write a very simple discord bot that says \"Hello {user_name}!\" to every new incoming message in a discord server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_xPdNDk_4OY"
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Bot:\n",
    "intents = discord.Intents.default()\n",
    "intents.message_content = True\n",
    "\n",
    "\n",
    "TOKEN = os.getenv('DISCORD_TOKEN')\n",
    "\n",
    "\n",
    "client = discord.Client(intents=intents)\n",
    "\n",
    "@client.event\n",
    "async def on_ready():\n",
    "    print(f'We have logged in as {client.user}')\n",
    "\n",
    "@client.event\n",
    "async def on_message(message):\n",
    "    if message.author == client.user:\n",
    "        return\n",
    "    await message.channel.send(f\"Hello, {message.author.global_name}!\")\n",
    "    return\n",
    "\n",
    "client.run(TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shZgOMw7_4fS"
   },
   "source": [
    "### Task 5\n",
    "Use LangChain to write a discord bot that will:\n",
    "- Greet a user, making a joke about their name and then proceed to answer any question they have, whenever a user sends a message.\n",
    "- Use async with langchain chain calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Wxh-dWx_4oy"
   },
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Session:\n",
    "CHAT_CACHE: Dict[str, List[str]] = {}\n",
    "\n",
    "chat = chat_models.ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "SPECIAL_SAUCE = \"Be kid-friendly.\"\n",
    "# SPECIAL_SAUCE = \"They are a priest.\"\n",
    "# SPECIAL_SAUCE = \"Roast them.\"\n",
    "# SPECIAL_SAUCE = \"Be absolutely brutal. Show no mercy, nor apologies.\"\n",
    "# SPECIAL_SAUCE = \"Make sure the joke would be awesome to tell during a job interview.\"\n",
    "# SPECIAL_SAUCE = \"\"\n",
    "system_prompt_template = \"Greet the discord user named {username} with a joke about their name.\"\n",
    "system_prompt_template = \" \".join([\n",
    "    system_prompt_template, \n",
    "    SPECIAL_SAUCE, \n",
    "    \"Do not respond with questions.\",\n",
    "])\n",
    "human_prompt_template = \"{text}\"\n",
    "\n",
    "def start_chat(who: str, text: str) -> str:\n",
    "    global CHAT_CACHE\n",
    "    CHAT_CACHE[who] = []\n",
    "    \n",
    "    system_prompt = SystemMessagePromptTemplate.from_template(system_prompt_template)\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "#     chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "#     resp = chain.run(username=who, text=text)\n",
    "    msgs = chat_prompt.format_prompt(username=who, text=text).to_messages()\n",
    "    resp = chat(msgs)\n",
    "    for msg in msgs:\n",
    "        CHAT_CACHE[who].append(msg)\n",
    "    CHAT_CACHE[who].append(resp)\n",
    "    return resp.content\n",
    "    \n",
    "\n",
    "def respond_to_model(who: str, text: str):\n",
    "    global CHAT_CACHE\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "    past_msgs = CHAT_CACHE[who]\n",
    "    print(past_msgs)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([*past_msgs, human_prompt])\n",
    "    msgs = chat_prompt.format_prompt(text=text).to_messages()\n",
    "    resp = chat(msgs)\n",
    "    for msg in msgs:\n",
    "        CHAT_CACHE[who].append(msg)\n",
    "    CHAT_CACHE[who].append(resp)\n",
    "    return resp.content\n",
    "\n",
    "\n",
    "def cleanup(who: str):\n",
    "    print(f\"cleaning up session with {who}\")\n",
    "    global CHAT_CACHE\n",
    "    del CHAT_CACHE[who]\n",
    "\n",
    "\n",
    "\n",
    "# Bot:\n",
    "intents = discord.Intents.default()\n",
    "intents.message_content = True\n",
    "\n",
    "\n",
    "TOKEN = os.getenv('DISCORD_TOKEN')\n",
    "\n",
    "\n",
    "client = discord.Client(intents=intents)\n",
    "\n",
    "@client.event\n",
    "async def on_ready():\n",
    "    print(f'We have logged in as {client.user}')\n",
    "\n",
    "@client.event\n",
    "async def on_message(message):\n",
    "    if message.author == client.user:\n",
    "        return\n",
    "    user = message.author.global_name\n",
    "    text = message.content\n",
    "    if user in CHAT_CACHE.keys():\n",
    "        ai_response = respond_to_model(user, text)\n",
    "        await message.channel.send(ai_response)\n",
    "        cleanup(user)\n",
    "    else:\n",
    "        ai_response = start_chat(user, text)\n",
    "        await message.channel.send(ai_response)\n",
    "    return\n",
    "\n",
    "client.run(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxofoCWyCw6t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
